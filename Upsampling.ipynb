{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "882f9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 2023\n",
    "# Upsamling is explained here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b2e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b497075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19726b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upsample(scale_factor=1.0, mode=nearest)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsample_layer = torch.nn.Upsample(scale_factor=1, mode='nearest')\n",
    "upsample_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8df88261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can either give a scale_factor or the target output size to calculate \n",
    "# the output size. (You cannot give both, as it is ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cfb4fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upsample(size=(10, 10), mode=nearest)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsample_layer = torch.nn.Upsample(size=(10,10), mode='nearest')\n",
    "upsample_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122e202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97f45414",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((1, 1, 10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e5888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e278a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f3974d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae1f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36d40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07f67706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the benefit of upsampling with scale_factor=1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0c6a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlayer = torch.nn.Sequential(\n",
    "            torch.nn.Upsample(scale_factor=1, mode='nearest'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91540db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlayer(img).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c60f60b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img -convlayer(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a2d6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlayer = torch.nn.Sequential(\n",
    "            torch.nn.Upsample(size=(12,12), mode='nearest'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdbe7fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12, 12])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlayer(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f049fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "# One can either give a scale_factor or the target output size to calculate \n",
    "# the output size. (You cannot give both, as it is ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd96ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aabe4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you must wonder why scale_factor can be chosen as any floating number!\n",
    "# So, in general you can see that the depth, width, and height are computed in this way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923ff61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula is:\n",
    "# D_out = floor(D_in*scale_factor)\n",
    "# W_out = floor(W_in*scale_factor)\n",
    "# H_out = floor(H_in*scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5faaa0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upsample(scale_factor=1.0, mode=nearest)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nn.Upsample(scale_factor=1, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e7812c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsam_layer = nn.Upsample(scale_factor=1.725, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50ea3360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 10, 10]), torch.Size([1, 1, 17, 17]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape, upsam_layer(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac08bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb57d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bd0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa1e31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following layer downsample the input with 1 pixel in each w and h\n",
    "# since maxpooling has no padding. That is quite obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb99438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 =  torch.nn.Sequential(\n",
    "\n",
    "            torch.nn.MaxPool2d(2, stride=1),\n",
    "   \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7690c672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 10, 10]), torch.Size([1, 1, 9, 9]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see: the dim is decreased\n",
    "img.shape, layer1(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a64c2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to recover the dims this I can use nn.Upsampling\n",
    "# I say Ok, I need dim_out = 10 and I will put it in \n",
    "# the formula dim_out= floor(d_in*scale_factor) and solve\n",
    "# it for scale_factor: The scale_factor must fit in  10/9 <= scal_fact < 11/9.\n",
    "# I obtained 1.166 for this scale_factor. Any number lower that this \n",
    "# cannot be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "15cd4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Upsample(scale_factor=1.1666, mode='nearest'),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2386f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5a41258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2(layer1(img)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c39ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "251f67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Upsample(scale_factor=1, mode='nearest'),\n",
    "            torch.nn.Conv2d(1, 1, kernel_size=(3,3), stride=1, padding=1),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c24aa154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 9, 9])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2(layer1(img)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c909d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
